{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc971af-12ae-472e-bf85-3ff51e886a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\eshad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\eshad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "from occupationcoder.coder import SOCCoder\n",
    "from langdetect import detect, DetectorFactory\n",
    "from datetime import datetime\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce18ea0e-2d60-4e43-9d83-2755487102e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_paths = [\"C:\\\\Users\\\\eshad\\\\OneDrive\\\\Desktop\\\\TU Delft\\\\Thesis\\\\Web Scrape PoC\\\\Data\\\\1. Consolidated data\\\\2018\\\\data_2018 backup 29 march\\\\\"]\n",
    "save_path = \"C:\\\\Users\\\\eshad\\\\OneDrive\\\\Desktop\\\\TU Delft\\\\Thesis\\\\Web Scrape PoC\\\\Data\\\\2. Filtered preprocessed data\\\\2018\\\\2018_backup_29_mar.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91d60151-df7f-452c-9490-0efc4314cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be6bfcad-b415-49f8-88f5-7b09d6824d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_1.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_10.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_2.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_3.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_4.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_5.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_6.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_7.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_8.csv\n",
      "read C:\\Users\\eshad\\OneDrive\\Desktop\\TU Delft\\Thesis\\Web Scrape PoC\\Data\\1. Consolidated data\\2018\\data_2018 backup 29 march\\data_2018_9.csv\n",
      "84084\n"
     ]
    }
   ],
   "source": [
    "columns = ['jobPostingId', 'companyDetails', 'jobState', 'description', 'title', 'workRemoteAllowed', 'formattedLocation', 'workplaceTypesResolutionResults']\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "# Read each CSV file and append to the list\n",
    "for directory_path in directory_paths:\n",
    "    csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "    for csv_file in csv_files:\n",
    "        # if csv_file.endswith('7.csv') or csv_file.endswith('8.csv') or csv_file.endswith('9.csv') or csv_file.endswith('10.csv'): # or csv_file.endswith('4.csv') or csv_file.endswith('5.csv'):\n",
    "            file_path = os.path.join(directory_path, csv_file)\n",
    "            tmp_df = pd.read_csv(file_path, encoding='latin')\n",
    "            dataframes.append(tmp_df)\n",
    "            print(f\"read {file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "print(len(df))\n",
    "# df = df[columns]\n",
    "logs+=f\"Read {len(df)} rows files {csv_files} into df \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d04f0-dc3b-426f-8ec7-6bbf307036bb",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Language Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6348ef47-db7c-4694-b56e-c744253043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_eval_func(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x.replace(\"\\n\", \" \").replace(\"\\'False\\'\", \"\\\"FALSE\\\"\"))\n",
    "    except Exception as e:\n",
    "        return \"literal eval failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d05b0e4-2226-4d51-b315-92f6ee369410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['description'] = df['description'].apply(lambda x: ast.literal_eval(x))\n",
    "df['description'] = df['description'].apply(lambda x: literal_eval_func(x))\n",
    "df['description'] = df['description'].apply(lambda x: x['text'] if 'text' in x else None)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91c3f339-15e5-47cb-bf48-bc5595e23aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84084\n",
      "84084\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df[df['description']!=\"literal eval failed\"]\n",
    "df = df[~df['description'].isna()]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9b64d79-d077-40a3-b70a-461c72610043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84084\n"
     ]
    }
   ],
   "source": [
    "def extract_language(desc, title):\n",
    "    # if not desc or not title:\n",
    "        # return \"not found\"\n",
    "    try:\n",
    "        return detect(desc)\n",
    "    except:\n",
    "        try:\n",
    "            return detect(title)\n",
    "        except:\n",
    "            # print(title, desc)\n",
    "            return \"not found\"\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "df['language'] = df.apply(lambda x: extract_language(x['description'], x['title']), axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a05f3dc-90e1-4cf8-a726-1a7be899f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['language']==\"not found\"]))\n",
    "df[df['language']==\"not found\"]\n",
    "logs+=f\"Language not found for {len(df[df['language']==\"not found\"])} rows \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87557477-ff41-4733-9d4e-51959e1990f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75194\n"
     ]
    }
   ],
   "source": [
    "df_eng = df[df['language']==\"en\"]\n",
    "print(len(df_eng))\n",
    "logs+=f\"English language jobs: {len(df_eng)} rows \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "407e1f79-93ae-406b-ad76-0efd4813e687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n"
     ]
    }
   ],
   "source": [
    "myCoder = SOCCoder()\n",
    "df_eng['soc_code'] = df_eng.apply(lambda x: myCoder.code_record(str(x['title']), str(x['description'])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3131812f-8198-40d3-b6c4-3e8c85da325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_localized_name(dict):\n",
    "    try:\n",
    "        if  'On-site' in dict:\n",
    "            return 'On-site'\n",
    "        elif 'Hybrid' in dict:\n",
    "            return 'Hybrid'\n",
    "        elif 'Remote' in dict:\n",
    "            return 'Remote'\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_eng['work_model'] = df_eng['workplaceTypesResolutionResults'].apply(lambda x: extract_localized_name(x))\n",
    "# df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49de6633-72da-419a-ad59-eab23c972fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobPostingId</th>\n",
       "      <th>companyDetails</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>workRemoteAllowed</th>\n",
       "      <th>formattedLocation</th>\n",
       "      <th>work_model</th>\n",
       "      <th>soc_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589586880</td>\n",
       "      <td>{'com.linkedin.voyager.deco.jobs.web.shared.We...</td>\n",
       "      <td>Regulatory Affairs Project Manager</td>\n",
       "      <td>SUMMARY OF POSITION: \\n This position will be ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Mansfield, MA</td>\n",
       "      <td>None</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589586718</td>\n",
       "      <td>{'com.linkedin.voyager.deco.jobs.web.shared.We...</td>\n",
       "      <td>Senior Corporate Accountant</td>\n",
       "      <td>Location: Blue Bell, PA \\n Corporate Accountin...</td>\n",
       "      <td>False</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>None</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589586238</td>\n",
       "      <td>{'com.linkedin.voyager.deco.jobs.web.shared.We...</td>\n",
       "      <td>Sr. Transportation Engineer</td>\n",
       "      <td>Our Company is going through rapid growth and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Kirkland, WA</td>\n",
       "      <td>None</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>589586172</td>\n",
       "      <td>{'com.linkedin.voyager.deco.jobs.web.shared.We...</td>\n",
       "      <td>Programs Sales Manager</td>\n",
       "      <td>The District of Columbia Bar has an immediate ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>None</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589585092</td>\n",
       "      <td>{'com.linkedin.voyager.deco.jobs.web.shared.We...</td>\n",
       "      <td>Warranty Engineer</td>\n",
       "      <td>This position has direct responsibility to pla...</td>\n",
       "      <td>False</td>\n",
       "      <td>Plymouth, MI</td>\n",
       "      <td>None</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jobPostingId                                     companyDetails  \\\n",
       "0     589586880  {'com.linkedin.voyager.deco.jobs.web.shared.We...   \n",
       "1     589586718  {'com.linkedin.voyager.deco.jobs.web.shared.We...   \n",
       "2     589586238  {'com.linkedin.voyager.deco.jobs.web.shared.We...   \n",
       "3     589586172  {'com.linkedin.voyager.deco.jobs.web.shared.We...   \n",
       "4     589585092  {'com.linkedin.voyager.deco.jobs.web.shared.We...   \n",
       "\n",
       "                                title  \\\n",
       "0  Regulatory Affairs Project Manager   \n",
       "1         Senior Corporate Accountant   \n",
       "2         Sr. Transportation Engineer   \n",
       "3              Programs Sales Manager   \n",
       "4                   Warranty Engineer   \n",
       "\n",
       "                                         description  workRemoteAllowed  \\\n",
       "0  SUMMARY OF POSITION: \\n This position will be ...              False   \n",
       "1  Location: Blue Bell, PA \\n Corporate Accountin...              False   \n",
       "2  Our Company is going through rapid growth and ...              False   \n",
       "3  The District of Columbia Bar has an immediate ...              False   \n",
       "4  This position has direct responsibility to pla...              False   \n",
       "\n",
       "  formattedLocation work_model soc_code  \n",
       "0     Mansfield, MA       None      242  \n",
       "1  Philadelphia, PA       None      412  \n",
       "2      Kirkland, WA       None      212  \n",
       "3     Arlington, VA       None      354  \n",
       "4      Plymouth, MI       None      353  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng = df_eng[['jobPostingId', 'companyDetails', 'title', 'description', 'workRemoteAllowed', 'formattedLocation', 'work_model', 'soc_code']] \n",
    "# print(len(df_eng))\n",
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be4d70-10b3-46f7-86a0-daed58f4a21e",
   "metadata": {},
   "source": [
    "## Filtering SOC Code\n",
    "- SOC code filtered: 213\n",
    "- Keywords: ['devops', 'data science', 'data scientist', 'machine learning', 'site reliability', 'data analyst', 'data engineer', 'information technology', 'blockchain', 'cyber security', 'cybersecurity', 'database administrator', 'database admin', 'system administrator', 'system admin', 'systems admin', 'computer science', 'computer scientist', 'full stack', 'full-stack', 'back end', 'back-end', 'front end', 'front-end', 'mobile dev', 'game dev', 'graphics dev', 'cloud infrastructure', 'ai developer', 'qa dev', 'test dev']\n",
    "- \n",
    "['IT ', 'AI ', 'AI/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7131c13d-3261-44a9-bc20-2d4cd46dd144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75194"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3a7dcc4-163e-4ebd-8268-16b74390f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_to_retain = ['devops', 'data science', 'data scientist', 'machine learning', 'site reliability', 'data analyst', 'data engineer', 'information technology', 'blockchain', 'cyber security', 'cybersecurity', 'database administrator', 'database admin', 'system administrator', 'system admin', 'systems admin', 'computer science', 'computer scientist', 'full stack', 'full-stack', 'back end', 'back-end', 'front end', 'front-end', 'mobile dev', 'game dev', 'graphics dev', 'cloud infrastructure', 'ai developer', 'qa dev', 'test dev']\n",
    "case_sensitive_keywords_to_retain = ['IT ', 'AI ', 'AI/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8b14cfb-f1c5-41dc-b1c5-28183056a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devops|data science|data scientist|machine learning|site reliability|data analyst|data engineer|information technology|blockchain|cyber security|cybersecurity|database administrator|database admin|system administrator|system admin|systems admin|computer science|computer scientist|full stack|full-stack|back end|back-end|front end|front-end|mobile dev|game dev|graphics dev|cloud infrastructure|ai developer|qa dev|test dev\n",
      "IT |AI |AI/\n"
     ]
    }
   ],
   "source": [
    "pattern_keywords_to_retain = '|'.join(keywords_to_retain)\n",
    "pattern_case_sensitive_keywords_to_retain = '|'.join(case_sensitive_keywords_to_retain)\n",
    "print(pattern_keywords_to_retain)\n",
    "print(pattern_case_sensitive_keywords_to_retain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af252b7e-9138-4cc3-9c09-48bbefe8d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2396 921\n"
     ]
    }
   ],
   "source": [
    "cs_jobs_keywords_1 = df_eng[df_eng['title'].str.contains(pattern_keywords_to_retain, case=False, na=False)]\n",
    "cs_jobs_keywords_2 = df_eng[df_eng['title'].str.contains(pattern_case_sensitive_keywords_to_retain, case=True, na=False)]\n",
    "print(len(cs_jobs_keywords_1), len(cs_jobs_keywords_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70155857-a84c-43b8-8ab3-1012b5490c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12605\n"
     ]
    }
   ],
   "source": [
    "cs_jobs_code_213 = df_eng[df_eng['soc_code']=='213']\n",
    "print(len(cs_jobs_code_213))\n",
    "# cs_jobs_code_213.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b87552b-f474-4c51-99bf-86f706a941c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15922\n"
     ]
    }
   ],
   "source": [
    "cs_jobs = pd.concat([cs_jobs_keywords_1, cs_jobs_keywords_2, cs_jobs_code_213])\n",
    "print(len(cs_jobs))\n",
    "# cs_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cfe13e0f-d273-48c1-b090-0f964a837802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15922\n"
     ]
    }
   ],
   "source": [
    "logs+=f\"CS jobs found = {len(cs_jobs)} rows \\n\"\n",
    "print(len(cs_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9edc08fc-330b-4c45-a665-b3e82472bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_jobs.to_csv(f\"{save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c91ec-2f5e-428c-863f-8c51336acdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
